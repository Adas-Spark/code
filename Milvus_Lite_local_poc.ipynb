{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92245de-4b64-4ad2-9925-fa7d8706c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import model\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0616a9-2f9d-4955-b67c-5652e422076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your JSON file\n",
    "with open('example_QA_output.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3f201a-10ba-4594-a50a-3f44a2367c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 questions:\n",
      "Q1: What was Ada like as a person? (5 answers)\n",
      "Q2: What were Ada's favorite activities or things to do? (5 answers)\n",
      "Q3: How did Ada influence the community around her? (5 answers)\n",
      "Q4: How did Ada and her family cope with her illness and treatment? (5 answers)\n",
      "Q5: What specific moments or stories capture Ada's personality best? (5 answers)\n"
     ]
    }
   ],
   "source": [
    "# Extract question data\n",
    "print(f\"Loaded {len(data)} questions:\")\n",
    "for item in data:\n",
    "    print(f\"{item['question_id']}: {item['question_text']} ({len(item['answers'])} answers)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a65e4c-162a-4b37-bfbb-2d96009ac2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Milvus Lite instance\n",
    "client = MilvusClient(\"questions_db.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e7aa4a-04b7-4ea2-8526-96107bce70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# Use a more powerful model through SentenceTransformers directly\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Better for semantic search\n",
    "\n",
    "# Get the model dimension right away\n",
    "model_dimension = embedding_model.get_sentence_embedding_dimension()\n",
    "print(model_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2671a09-6c93-4f9c-8e17-81812a46da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the collection already exists, and delete it if it does\n",
    "if client.has_collection(collection_name=\"questions_collection\"):\n",
    "    client.drop_collection(collection_name=\"questions_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa518332-e2ce-4bdb-9988-10c3ec8e5ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection with dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Create a new collection with the correct dimension\n",
    "client.create_collection(\n",
    "    collection_name=\"questions_collection\",\n",
    "    dimension=model_dimension,  # Use the dimension from the model\n",
    "    metric_type=\"COSINE\"  # Change this to select a different metric\n",
    ")\n",
    "print(f\"Created collection with dimension: {model_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "621b35e8-bc42-4b85-97e2-9332cf5de615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that you may or may not want to normalize embeddings depending on a few factors, just make sure if you normalize here you normalize the query as well\n",
      "Actual embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all questions\n",
    "questions = [item['question_text'] for item in data]\n",
    "embeddings = embedding_model.encode(questions, normalize_embeddings=True)\n",
    "print(\"Note that you may or may not want to normalize embeddings depending on a few factors, just make sure if you normalize here you normalize the query as well\")\n",
    "\n",
    "# Print the actual dimension to verify\n",
    "print(f\"Actual embedding dimension: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc91e95-f141-4ca3-89b4-4285971fc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for insertion with answers as JSON\n",
    "milvus_data = [\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"vector\": embeddings[i],\n",
    "        \"question_id\": data[i]['question_id'],\n",
    "        \"question_text\": data[i]['question_text'],\n",
    "        \"category\": data[i]['category'],\n",
    "        \"answers_json\": json.dumps(data[i]['answers'])  # Store answers as JSON string\n",
    "    }\n",
    "    for i in range(len(data))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd69d9f6-58c1-4162-ace3-f2759498181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5 records with vector dimension 384\n"
     ]
    }
   ],
   "source": [
    "# Insert the data into the collection\n",
    "result = client.insert(collection_name=\"questions_collection\", data=milvus_data)\n",
    "print(f\"Inserted {result['insert_count']} records with vector dimension {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b725976e-4f6b-4790-a6b9-aeca4f5a505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for similar questions\n",
    "def search_similar_questions(query_text, limit=5, include_answers=True, normalize_embeddings=True):\n",
    "    \"\"\"\n",
    "    Search for questions similar to the query text\n",
    "    \n",
    "    Parameters:\n",
    "    - query_text: The text to search for\n",
    "    - limit: Maximum number of results to return\n",
    "    - include_answers: Whether to include answers in the results\n",
    "    - normalize_embeddings: Whether to normalize the query embeddings (default: True)\n",
    "\n",
    "    Returns:\n",
    "    - List of matching questions with their data\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query_text], normalize_embeddings=normalize_embeddings)\n",
    "    \n",
    "    output_fields = [\"question_id\", \"question_text\", \"category\"]\n",
    "    if include_answers:\n",
    "        output_fields.append(\"answers_json\")\n",
    "    \n",
    "    results = client.search(\n",
    "        collection_name=\"questions_collection\",\n",
    "        data=query_embedding,\n",
    "        limit=limit,\n",
    "        output_fields=output_fields\n",
    "    )\n",
    "    \n",
    "    # Parse the JSON string back to a list if answers are included\n",
    "    if include_answers and results and results[0]:\n",
    "        for res in results[0]:\n",
    "            if \"answers_json\" in res[\"entity\"]:\n",
    "                res[\"entity\"][\"answers\"] = json.loads(res[\"entity\"][\"answers_json\"])\n",
    "                del res[\"entity\"][\"answers_json\"]  # Remove the JSON string field\n",
    "    \n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a4160-cc03-44ef-b376-ecdfa3bb1b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1323737d-da5c-4444-81c3-9c94d644c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Search Results:\n",
      "Query: 'What was Ada's personality like?'\n",
      "Top matches:\n",
      "Question ID: Q1\n",
      "Question: What was Ada like as a person?\n",
      "Category: character\n",
      "Similarity Score: 0.1082\n",
      "Number of answers: 5\n",
      "First answer: Ada was a beacon of unwavering spirit and resilience. Even when faced with the intense pain and naus...\n",
      "---\n",
      "Question ID: Q5\n",
      "Question: What specific moments or stories capture Ada's personality best?\n",
      "Category: moments\n",
      "Similarity Score: 0.1484\n",
      "Number of answers: 5\n",
      "First answer: Even in her final days, when pain was severe and doctors thought the end was near, Ada's vibrant spi...\n",
      "---\n",
      "Question ID: Q3\n",
      "Question: How did Ada influence the community around her?\n",
      "Category: influence\n",
      "Similarity Score: 0.2171\n",
      "Number of answers: 5\n",
      "First answer: Ada's courageous fight against leukemia inspired her family to establish 'Ada's Spark,' a non-profit...\n",
      "---\n",
      "Question ID: Q2\n",
      "Question: What were Ada's favorite activities or things to do?\n",
      "Category: activities\n",
      "Similarity Score: 0.2287\n",
      "Number of answers: 5\n",
      "First answer: Ada adored riding her bike, a simple joy that became a symbol of her resilience. Even while undergoi...\n",
      "---\n",
      "Question ID: Q4\n",
      "Question: How did Ada and her family cope with her illness and treatment?\n",
      "Category: coping\n",
      "Similarity Score: 0.2992\n",
      "Number of answers: 5\n",
      "First answer: Ada and her family adopted the mantra \"Life isn't about waiting for the storm to pass...It's about l...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test the search function\n",
    "#test_query = \"What was Ada like as a person?\"\n",
    "test_query = \"What was Ada's personality like?\"\n",
    "search_results = search_similar_questions(test_query)\n",
    "\n",
    "print(\"\\nTest Search Results:\")\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(\"Top matches:\")\n",
    "for result in search_results:\n",
    "    print(f\"Question ID: {result['entity']['question_id']}\")\n",
    "    print(f\"Question: {result['entity']['question_text']}\")\n",
    "    print(f\"Category: {result['entity']['category']}\")\n",
    "    print(f\"Similarity Score: {1-result['distance']:.4f}\")\n",
    "    \n",
    "    if \"answers\" in result[\"entity\"]:\n",
    "        print(f\"Number of answers: {len(result['entity']['answers'])}\")\n",
    "        # Show first answer as example\n",
    "        if result['entity']['answers']:\n",
    "            first_answer = result['entity']['answers'][0]\n",
    "            print(f\"First answer: {first_answer['answer_text'][:100]}...\")  # Show first 100 chars\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca99f72-c50b-45e6-adf9-1976a5139178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687df272-5bd9-457a-8cbb-2105604a562f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f3c71-726f-4c65-a853-307a1fb01b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f79d92-4404-4f0f-9bd7-6f13b71c0515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a13a56-cebb-45b1-86d4-5d6ae2325258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
