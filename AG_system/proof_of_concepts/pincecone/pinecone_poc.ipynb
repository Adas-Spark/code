{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffee8d-4d1a-4f9a-9865-899e026072e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Ada's Spark Memory Pinecone POC\n",
    "# \n",
    "# This notebook implements a proof-of-concept using Pinecone to create a vector database for Ada's memory.\n",
    "# \n",
    "# ## Setup Instructions\n",
    "# \n",
    "# ### 1. Install Required Packages\n",
    "# \n",
    "# Run the following in your terminal or in a notebook cell:\n",
    "# ```\n",
    "# pip install --upgrade pinecone python-dotenv tqdm\n",
    "# ```\n",
    "# \n",
    "# ### 2. Create a .env File\n",
    "# \n",
    "# Create a file named `.env` in the same directory as this notebook with your Pinecone API key:\n",
    "# ```\n",
    "# PINECONE_API_KEY=your_api_key_here\n",
    "# ```\n",
    "# \n",
    "# ### 3. Run the Notebook\n",
    "# \n",
    "# Execute the cells below to create your Pinecone vector database and test search capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b5072-5e71-48cb-89f1-b249c5b62b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On my personal machine: conda activate pinecone_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73c8ec-5ea7-45b8-8e91-3687835f61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff7cdf-454d-4eb7-94a1-949a52007c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your JSON file\n",
    "with open('../generated_qa_pairs_combined_clean_20250603_214922.json', 'r') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6e34f-ce2e-4189-92d5-d241d3a0c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract question data\n",
    "print(f\"Loaded {len(data)} questions:\")\n",
    "for item in data:\n",
    "    print(f\"{item['question_id']}: {item['question_text']} ({len(item['answers'])} answers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e90d06-f6e5-47f9-afe4-96d67d97b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179c6ec-2126-40ed-bca1-fdc620189bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client using API key from environment variables\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac187418-0522-499b-b674-f900a1762515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check existing indexes\n",
    "print(\"Existing indexes:\", pc.list_indexes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67939b-53df-4d2e-9773-561339c5decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding model to use\n",
    "model_name = \"llama-text-embed-v2\"\n",
    "\n",
    "# For llama-text-embed-v2, the dimension is 1024\n",
    "model_dimension = 1024\n",
    "\n",
    "print(f\"Using embedding model: {model_name} with dimension {model_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228ea87-9551-47e0-bd0a-64b3ea793d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the embedding API with a simple example to verify it works\n",
    "try:\n",
    "    test_embed = pc.inference.embed(\n",
    "        model=model_name,\n",
    "        inputs=[\"This is a test sentence.\"],\n",
    "        parameters={\"input_type\": \"passage\"}\n",
    "    )\n",
    "    print(f\"✅ Embedding API test successful!\")\n",
    "    \n",
    "    # Access the values correctly based on the returned object type\n",
    "    if hasattr(test_embed[0], 'values'):\n",
    "        # New Pinecone client returns structured objects\n",
    "        vector_values = test_embed[0].values\n",
    "        actual_dimension = len(vector_values)\n",
    "        print(f\"  Produced a vector with dimension: {actual_dimension}\")\n",
    "    else:\n",
    "        # Direct access if it's already a vector\n",
    "        vector_values = test_embed[0]\n",
    "        actual_dimension = len(vector_values)\n",
    "        print(f\"  Produced a vector with dimension: {actual_dimension}\")\n",
    "    \n",
    "    # Verify dimension matches expected\n",
    "    if actual_dimension != model_dimension:\n",
    "        print(f\"⚠️ Warning: Actual dimension ({actual_dimension}) doesn't match expected ({model_dimension})\")\n",
    "        # Update model_dimension to the actual value\n",
    "        model_dimension = actual_dimension\n",
    "        print(f\"  Updated model_dimension to: {model_dimension}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Embedding API test failed: {str(e)}\")\n",
    "    print(\"  Check your API key and model availability in your Pinecone account.\")\n",
    "    # Print the type and structure of the response for debugging\n",
    "    if 'test_embed' in locals():\n",
    "        print(f\"  Response type: {type(test_embed)}\")\n",
    "        print(f\"  First item type: {type(test_embed[0])}\")\n",
    "        print(f\"  Response structure: {dir(test_embed[0])}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc462a86-1b6a-48b3-8236-70608cd013b8",
   "metadata": {},
   "source": [
    "### Create Pinecone Index\n",
    "Now let's create a Pinecone index to store our question/answer embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87abf85-adc8-4a2d-b156-ea7ff5093132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index name\n",
    "index_name = \"adas-memory-qa-poc\"\n",
    "\n",
    "# Check if the index already exists and delete it if needed\n",
    "if index_name in [index.name for index in pc.list_indexes()]:\n",
    "    print(f\"Deleting existing index: {index_name}\")\n",
    "    pc.delete_index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6c162-00c4-41f9-a11a-14f8c7661f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Pinecone serverless index\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=model_dimension,  # Use the dimension from the model\n",
    "    metric=\"cosine\",  # Change to match your desired similarity metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"  # Choose the region closest to you\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created index '{index_name}' with dimension {model_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa0a74-9687-4727-989d-c26cfb5b656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the newly created index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Check if the index is ready\n",
    "index_stats = index.describe_index_stats()\n",
    "print(f\"Index stats: {index_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a86a4-cb4b-4091-97ab-2f4584bbcd72",
   "metadata": {},
   "source": [
    "### Generate Embeddings and Insert Data\n",
    " \n",
    "Now let's generate embeddings for all questions and insert them into Pinecone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526682c1-c754-4726-8cef-ce309c1bb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all questions using Pinecone's hosted models\n",
    "questions = [item['question_text'] for item in data]\n",
    "print(f\"Generating embeddings for {len(questions)} questions using {model_name}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775d41c-bf6c-4496-adac-9890c38f201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings in batches to respect API limits\n",
    "def generate_embeddings_in_batches(texts, model_name, batch_size=90):\n",
    "    \"\"\"\n",
    "    Generate embeddings in batches to respect API limits\n",
    "    Using batch_size=90 to stay safely under the 96 limit\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    print(f\"Generating embeddings for {len(texts)} questions in batches of {batch_size}...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        # Generate embeddings for this batch\n",
    "        batch_response = pc.inference.embed(\n",
    "            model=model_name,\n",
    "            inputs=batch,\n",
    "            parameters={\"input_type\": \"query\"}\n",
    "        )\n",
    "        \n",
    "        # Extract embeddings from batch response\n",
    "        batch_embeddings = []\n",
    "        for embedding_obj in batch_response:\n",
    "            if hasattr(embedding_obj, 'values'):\n",
    "                batch_embeddings.append(embedding_obj.values)\n",
    "            else:\n",
    "                batch_embeddings.append(embedding_obj)\n",
    "        \n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        # Small delay to be nice to the API\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa36f0-73df-4842-a989-99135de03b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the batched function\n",
    "embeddings = generate_embeddings_in_batches(questions, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd392f1a-1fe0-445c-a2c2-14c0b5bbeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generated {len(embeddings)} embeddings of dimension {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00552d2b-86dc-4dd2-991f-7bd90faad95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we got the expected dimension\n",
    "if len(embeddings[0]) != model_dimension:\n",
    "    print(f\"Warning: Embedding dimension ({len(embeddings[0])}) doesn't match expected dimension ({model_dimension})\")\n",
    "    # Update model_dimension to the actual value\n",
    "    model_dimension = len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c08f5-9f00-4db8-8ee9-39003455200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for insertion\n",
    "pinecone_records = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    # Store answers as JSON string since Pinecone metadata has size limits\n",
    "    record = {\n",
    "        \"id\": item['question_id'],  # Using question_id as the vector ID\n",
    "        \"values\": embeddings[i],    # Vector values from the embeddings list\n",
    "        \"metadata\": {\n",
    "            \"question_text\": item['question_text'],\n",
    "            \"category\": item['category'],\n",
    "            \"answers_json\": json.dumps(item['answers'])  # Store answers as JSON string\n",
    "        }\n",
    "    }\n",
    "    pinecone_records.append(record)\n",
    "\n",
    "print(f\"Prepared {len(pinecone_records)} records for insertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ee069-5297-4460-b5a2-cd5603b406ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into Pinecone\n",
    "# Note: Pinecone accepts batches of up to 100 vectors, so we'll insert in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(pinecone_records), batch_size):\n",
    "    batch = pinecone_records[i:i+batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(f\"Inserted {len(pinecone_records)} records into Pinecone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397ed0b-6e57-434a-8278-02877f30a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait a moment for indexing to complete\n",
    "print(\"Waiting for indexing to complete...\")\n",
    "time.sleep(10)  # Adding a delay to ensure indexing completes\n",
    "print(\"Waiting complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbab672-f99e-4178-9fb1-d11efe4d7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify insertion\n",
    "index_stats = index.describe_index_stats()\n",
    "print(f\"Index now contains {index_stats['total_vector_count']} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843733b1-572b-4649-88e1-89337adba780",
   "metadata": {},
   "source": [
    "### Search Function\n",
    "\n",
    "Let's create a function to search for similar questions based on user queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0d8cd-5423-4cb6-b4b1-d49fc21cdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_questions(query_text, limit=5, include_answers=True):\n",
    "    \"\"\"\n",
    "    Search for questions similar to the query text\n",
    "    \n",
    "    Parameters:\n",
    "    - query_text: The text to search for\n",
    "    - limit: Maximum number of results to return\n",
    "    - include_answers: Whether to include answers in the results\n",
    "\n",
    "    Returns:\n",
    "    - List of matching questions with their data\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query using Pinecone's hosted model\n",
    "    query_embedding = pc.inference.embed(\n",
    "        model=model_name,\n",
    "        inputs=[query_text],\n",
    "        parameters={\"input_type\": \"query\"}  # Changed from \"passage\" to \"query\"\n",
    "    )\n",
    "    \n",
    "    # Extract vector values correctly\n",
    "    if hasattr(query_embedding[0], 'values'):\n",
    "        query_vector = query_embedding[0].values\n",
    "    else:\n",
    "        query_vector = query_embedding[0]\n",
    "    \n",
    "    # Search Pinecone\n",
    "    results = index.query(\n",
    "        vector=query_vector,\n",
    "        top_k=limit,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Process results\n",
    "    formatted_results = []\n",
    "    for match in results.matches:\n",
    "        result_item = {\n",
    "            \"question_id\": match.id,\n",
    "            \"question_text\": match.metadata.get(\"question_text\", \"\"),\n",
    "            \"category\": match.metadata.get(\"category\", \"\"),\n",
    "            \"score\": match.score,  # Cosine similarity score\n",
    "        }\n",
    "        \n",
    "        # Parse the JSON string back to a list if answers are included\n",
    "        if include_answers and \"answers_json\" in match.metadata:\n",
    "            result_item[\"answers\"] = json.loads(match.metadata[\"answers_json\"])\n",
    "            \n",
    "        formatted_results.append(result_item)\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d94db-78f1-45d7-a9c6-417c6c9a1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the search function with various queries\n",
    "test_queries = [\n",
    "    \"What was Ada's personality like?\",\n",
    "    \"What was Ada like as a person?\",\n",
    "    \"How did Ada have fun during treatment?\",\n",
    "    \"What were Ada's favorite activities or things to do?\",\n",
    "    \"What impact did Ada have on people around her?\",\n",
    "    \"Tell me about a funny Ada story\",\n",
    "    \"How did the family handle difficult times?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad485f-24b5-43ac-a96c-242a93932edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in test_queries:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = search_similar_questions(query, limit=2)\n",
    "    \n",
    "    print(\"\\nTop matches:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\n{i+1}. Question ID: {result['question_id']}\")\n",
    "        print(f\"   Question: {result['question_text']}\")\n",
    "        print(f\"   Category: {result['category']}\")\n",
    "        print(f\"   Similarity Score: {result['score']:.4f}\")\n",
    "        \n",
    "        if \"answers\" in result:\n",
    "            print(f\"   Number of answers: {len(result['answers'])}\")\n",
    "            # Show first answer as example\n",
    "            if result['answers']:\n",
    "                first_answer = result['answers'][0]\n",
    "                print(f\"   First answer: {first_answer['answer_text'][:200]}...\" if len(first_answer['answer_text']) > 200 \n",
    "                      else f\"   First answer: {first_answer['answer_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6720b9b-8bc6-4f0b-b737-571d33ac9eb0",
   "metadata": {},
   "source": [
    "# Potential Future Directions to Improve Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d9ea3-a4f8-40ef-a7a4-d31d98653297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see chat here for more details: https://claude.ai/chat/ee414354-7c79-40d3-9806-6cda04792aaf\n",
    "\n",
    "# FUTURE IMPROVEMENTS\n",
    "# ==================\n",
    "#\n",
    "# 1. Hybrid Search\n",
    "#    Implement hybrid search to combine vector similarity with keyword matching.\n",
    "#    This helps when users use different terminology than what's in our questions.\n",
    "#\n",
    "# 2. Basic Re-ranking\n",
    "#    Add post-processing that re-ranks results based on exact phrase matches,\n",
    "#    keyword overlap, and category-specific boosts. This can improve relevancy\n",
    "#    without external APIs.\n",
    "#\n",
    "# 3. Question Expansion\n",
    "#    Generate alternative phrasings for each question in the dataset.\n",
    "#    For example, \"What was Ada like?\" could become \"Tell me about Ada's personality\".\n",
    "#    This creates more entry points for queries.\n",
    "#\n",
    "# 4. Synonym Handling\n",
    "#    Create mappings of synonyms for important terms (e.g., \"funny\" → \"humorous\",\n",
    "#    \"activities\" → \"hobbies\"). Expand queries with these synonyms to improve matching.\n",
    "#\n",
    "# 5. Multi-Strategy Search\n",
    "#    Try several search approaches in parallel (vector, hybrid, expanded) and\n",
    "#    combine the results with different weights.\n",
    "#\n",
    "# 6. Content Expansion\n",
    "#    Add more questions and answers to the dataset. Search quality typically\n",
    "#    improves dramatically with more content, especially when targeting different\n",
    "#    ways people might phrase the same question.\n",
    "#\n",
    "# 7. Track & Learn from Queries\n",
    "#    Log actual search queries and use them to identify gaps in coverage.\n",
    "#    Add new questions based on common user searches.\n",
    "#\n",
    "# 8. Parameter Tuning\n",
    "#    Experiment with different values for hybrid search alpha, re-ranking weights,\n",
    "#    and similarity thresholds to optimize for our specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd26ac7-711d-442d-8c26-329dab3a1d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
